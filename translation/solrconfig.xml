<?xml version="1.0" encoding="UTF-8" ?>
<!--
 使用ASF下的一个或多个授权方式。查看其他所有权信息清查看本项目的声明文件。
 本项目使用ASF 2.0授权协议。您应遵守该协议。详细信息参加：

     http://www.apache.org/licenses/LICENSE-2.0

 除法律原因和书面许可外，该协议下软件的发布将遵循此协议,包括任何条件和情况在内。
 具体细节请查看协议内关于允许和禁止的相关描述。
-->

<!-- 
     更多细节清查看：http://wiki.apache.org/solr/SolrConfigXml. 
-->
<config>
  <!-- 在下面的配置中，类名前的"solr."前缀指代搜索相关的包，这些包可以在
       org.apache.solr.(search|update|request|core|analysis)中找到。

       如果你有自己定制的插件，你也可以写完整类名。
  -->

  <!-- 管理Solr附加的各种Lucene组件的版本。一般来说，你想要使用修复所有BUG和
       各种改进的最新版本。强烈推荐你在进行升级之后重新进行索引，以免在升级之
       后影响文本的所以和搜索。
  -->
  <luceneMatchVersion>LUCENE_50</luceneMatchVersion>

  <!-- lib管理能够用来指明Solr载入一个jars包并将其作为一个插件。这种声明
       在你的solrconfig.xml或者schema.xml中(ie:Analyzers,Request Handlers等)。

       所有目录和路径都关联为实例目录。

       如果"./lib"在你的实例目录中已经存在，其中的所有文件都可以通过以下语法
       找到...
       
              <lib dir="./lib" />
    -->

  <!--
    每一个自己加的'dir'选项都会添加到类路径里，这在包含某个目录所有jars包是很有用。
    如下：
    -->

  <!--
     <lib dir="../add-everything-found-in-this-dir-to-the-classpath" />
  -->

  <!-- 当你在一个'dir'配置项里指定了'regex'参数，则只有该目录下完全匹配此正则的文件
       才会被包含。
    -->
  <lib dir="../../dist/" regex="apache-solr-cell-\d.*\.jar" />
  <lib dir="../../contrib/extraction/lib" regex=".*\.jar" />

  <lib dir="../../dist/" regex="apache-solr-clustering-\d.*\.jar" />
  <lib dir="../../contrib/clustering/lib/" regex=".*\.jar" />

  <lib dir="../../dist/" regex="apache-solr-langid-\d.*\.jar" />
  <lib dir="../../contrib/langid/lib/" regex=".*\.jar" />

  <lib dir="../../dist/" regex="apache-solr-velocity-\d.*\.jar" />
  <lib dir="../../contrib/velocity/lib" regex=".*\.jar" />

  <!--
    如果一个'dir'配置项（不论有没有'regex'）被包含了而且没有找到匹配文件，则会被忽略。
    -->
  <lib dir="/total/crap/dir/ignored" /> 

  <!--
    准确'path'可以代替'dir'来指明一个文件。如果这个文件无法载入，会记录一条严重错误。
    -->
  <!--
     <lib path="../a-jar-that-does-not-exist.jar" /> 
  -->
  
  <!-- 数据目录

       用来声明除Solr根目录下'./data'以外的目录来保存索引数据。如果使用俄同步，这会匹
       配replication配置。
    -->
  <dataDir>${solr.data.dir:}</dataDir>


  <!-- 用在索引上的DirectoryFactory。

       solr.StandardDirectoryFactory，作为默认选择，是基于文件系统的，并且是目前JVM和平台
       的最好的实现。你可以强制使用以下实现：solr.MMapDirectoryFactory,solr.NIOFSDirectoryFactory,
       solr.SimpleFSDirectoryFactory。

       solr.RAMDirectoryFactory是基于内存的，不持久的，并且的不能使用replication。
    -->
  <directoryFactory name="DirectoryFactory" 
                    class="${solr.directoryFactory:solr.StandardDirectoryFactory}"/>

  <!-- ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
       索引配置 - 这些设置控制索引中的低位行为。这里大多数配置例子都使用默认值，但是都
       被注释掉了，这是为了更简单的看到哪里可以自定义设置。
       
       注意：这里相比旧版本替换了<indexDefaults>和<mainIndex>
       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ -->
  <indexConfig>
    <!-- maxFieldLength 指明索引中每个字段 *tokens* 的最大数量。默认值：10000 -->
    <!-- <maxFieldLength>10000</maxFieldLength>  -->

    <!-- 一个索引写入器为一个锁定写入可以等待的最大时间(ms)。默认值：1000 -->
    <!-- <writeLockTimeout>1000</writeLockTimeout>  -->

    <!-- 进阶配置：使用复合文件可以使用更少的索引文件，更少的文件可以降低系统开销。
         在Lucene里默认是"true"。在Solr里面默认是"false"(从3.6开始)-->
    <!-- <useCompoundFile>false</useCompoundFile> -->

    <!-- ramBufferSizeMB设置Lucene在添加和删除文档之后、刷新到目录之前缓冲区所用的
         内存大小。
         maxBufferedDocs限制在刷新之前文档缓冲区缓冲的文档数量。
         如果以上两个设置使用了，那么Lucene会基于先命中的那个配置来刷新。-->
    <!-- <ramBufferSizeMB>32</ramBufferSizeMB> -->
    <!-- <maxBufferedDocs>1000</maxBufferedDocs> -->

    <!-- 进阶配置：合并策略
         Lucene合并策略控制多个片段的合并。
         Solr/Lucene 3.3时的默认值是TieredMergePolicy。
         Lucene 2.3时的默认值是LogByteSizeMergePolicy。
         更老的Lucene版本LogDocMergePolicy。
    -->
    <!--
        <mergePolicy class="org.apache.lucene.index.TieredMergePolicy">
          <int name="maxMergeAtOnce">10</int>
          <int name="segmentsPerTier">10</int>
        </mergePolicy>
      -->
       
    <!-- 合并因子
         合并因子控制一次合并操作合并多少个片段。
         对于TieredMergePolicy,合并因子很简单就是MaxMergeAtOnce与SegmentsPerTier之和。
         对于LogByteSizeMergePolicy,合并因子决定合并之前允许有多少个片段。
         两种策略的默认值都是10。
      -->
    <!-- 
        <mergeFactor>10</mergeFactor>
      -->

    <!-- 进阶配置：合并安排 
         Lucene里的合并安排控制合并操作的进行。ConcurrentMergeScheduler(Lucene 2.3时的默认值)
         可以在后台用子进程执行合并操作。而SerialMergeScheduler(Lucene 2.2默认值)则
         做不到。
     -->
    <!-- 
       <mergeScheduler class="org.apache.lucene.index.ConcurrentMergeScheduler"/>
       -->

    <!-- LockFactory
         
         这个选项指明Lucene里面LockFactory的实现。

         single = SingleInstanceLockFactory - 适用于只读索引或不会被其他进程修改的索引。

         native = NativeFSLockFactory - 使用系统本地文件锁。当多个Solr应用在同一个
                  JVM试图共享一个索引的情况下不要用这个锁。
         simple = SimpleFSLockFactory - 使用文本文件锁定。

         默认值：Solr3.6以及更新的版本使用'native',其他版本使用'simple'。

         更多细节参阅：
         http://wiki.apache.org/lucene-java/AvailableLockFactories
    -->
    <!-- <lockType>native</lockType> -->

    <!-- 启动解锁

         如果设置为true,启动时会解锁任何写/提交锁。这会是多进程安全访问lucene索引的
         机制失效，所以慎用。默认值："false"。

         如果锁类型为"none"或者"single"这个就没必要了。
    -->
    <!--
    <unlockOnStartup>false</unlockOnStartup>
      -->
    
    <!-- 进阶配置：控制Lucene将术语导入内存的频率。
         默认是128，对大多数人来说都是比较合适的。
      -->
    <!-- <termIndexInterval>128</termIndexInterval> -->

    <!-- reopenReaders

         如果为"true"，索引读取器会重开（通常会更高效）而不是关闭后再开。
         默认值："true"。
      -->
    <!-- 
    <reopenReaders>true</reopenReaders>
      -->

    <!-- 提交删除策略
         
         这里可以指定自定义删除策略。自定义类必须实现 org.apache.lucene.index.IndexDeletionPolicy。

         http://lucene.apache.org/java/3_5_0/api/core/org/apache/lucene/index/IndexDeletionPolicy.html

         默认Solr IndexDeletionPolicy实现支持根据提交号码、提交点age和最优化状态来删除索引。

         最新提交点应该无视规则一直保持。
      -->
    <!-- 
    <deletionPolicy class="solr.SolrDeletionPolicy">
    -->
      <!-- 要保持的提交点的号码 -->
      <!-- <str name="maxCommitsToKeep">1</str> -->

      <!-- 要保持的优化提交点的号码 -->
      <!-- <str name="maxOptimizedCommitsToKeep">0</str> -->

      <!-- 
          一旦提交点提交到给定age，就删除所有提交点。
          支持DateMathParser语法，例如：
        -->
      <!--
         <str name="maxCommitAge">30MINUTES</str>
         <str name="maxCommitAge">1DAY</str>
      -->
    <!-- 
    </deletionPolicy>
    -->

     <!-- Lucene 信息流

         为了支持高级调试，Lucene提供了一个"Infostream"，包含了索引时的细节信息。

         设置值为"true"可以指示Lucene底层IndexWriter将调试信息写到指定文件内。
      -->
     <!-- <infoStream file="INFOSTREAM.txt">false</infoStream> --> 
  </indexConfig>

  <!-- JMX
       
       这个例子启用了JMX。如果有MBeanServer，则可以通过JVM参数来配置JMX。
       删除这个可以禁止Solr的配置和统计信息到JMX里。

       更多细节请看 http://wiki.apache.org/solr/SolrJmx
    -->
  <jmx />
  <!-- 如果你想连接特殊服务器，在这里指明agentId。 -->
  <!-- <jmx agentId="myAgent" /> -->

  <!-- 如果你想启动一个新的MBeanServer,在这里指明服务URL。 -->
  <!-- <jmx serviceUrl="service:jmx:rmi:///jndi/rmi://localhost:9999/solr"/> -->

  <!-- 默认高性能更新处理器 -->
  <updateHandler class="solr.DirectUpdateHandler2">

     <!-- 自动提交

          在特定条件下执行一个硬提交。如果不用自动提交，可以使用"commitWithin"在
          添加文档时提交。

          http://wiki.apache.org/solr/UpdateXmlMessages

          maxDocs - 一次自动提交可以提交的文档数量。

          maxTime - 添加操作多久之后进行自动提交，单位：ms

          openSearcher - 如果为false，提交会促使索引变化并刷新到稳定存储介质中，但是
                         不会打开新的搜索器使这些变化可见。
     
       -->
     <autoCommit> 
       <maxTime>15000</maxTime> 
       <openSearcher>false</openSearcher> 
     </autoCommit>

    <!-- softAutoCommit与autoCommit类似，但是它会进行"soft"提交。"soft"提交只保证变化可见，不
         保证数据同步到硬盘上。这个会更快更实时，比硬提交更友好些。
      -->
     <!--
       <autoSoftCommit> 
         <maxTime>1000</maxTime> 
       </autoSoftCommit>
      -->

    <!-- 根据事件来更新

         很多事件关联的IndexWriter能够触发监听器来执行动作。

         postCommit - 每次提交或优化后触发。
         postOptimize - 每次优化命令后触发。
      -->

    <!-- RunExecutableListener在控制台内执行一条来自postCommit或postOptimize的命令。

         exe - 要执行命令的名字
         dir - 当前工作目录。（默认值="."）
         wait - 请求进程是否等待执行结果。（默认值="true"）
         args - 传给程序的参数。（默认为none）
         env - 要设置的环境变量。（默认为none）
      -->

    <!-- 这个例子展示了RunExecutableListener可以通过基于replication的脚本来执行：

         http://wiki.apache.org/solr/CollectionDistribution
      -->
    <!--
       <listener event="postCommit" class="solr.RunExecutableListener">
         <str name="exe">solr/bin/snapshooter</str>
         <str name="dir">.</str>
         <bool name="wait">true</bool>
         <arr name="args"> <str>arg1</str> <str>arg2</str> </arr>
         <arr name="env"> <str>MYVAR=val1</str> </arr>
       </listener>
      -->

    <!-- 启用事务日志，当前是实时方式。

         "dir" - 事务日志的目标路径，默认是solr数据目录。
      -->
    <updateLog>
      <str name="dir">${solr.data.dir:}</str>
    </updateLog>
   

  </updateHandler>
  
  <!-- IndexReaderFactory

       通过下面的格式来指明一个自定义IndexReaderFactory,可以使用可选IndexReader实现。

       **实验特性**

       请注意 - 使用自定义IndexReaderFactory有可能会妨碍其他特性的正常工作。IndexReaderFactory
       的API会无提醒的发生变化，甚至在问题无法解决的情况下在未来的版本中移除。

       ** 使用自定义IndexReaderFactory的特性可能没生效 **

       ReplicationHandler假定有一个存放到硬盘上的索引。使用自定义IndexReader有可能导致
       ReplicationHandler不兼容从而导致replication特性无法正常工作。
       细节请看：SOLR-1366
    -->
  <!--
  <indexReaderFactory name="IndexReaderFactory" class="package.class">
    <str name="someArg">Some Value</str>
  </indexReaderFactory >
  -->
  <!-- 通过明确声明工厂，termIndexDivisor可以被指明。
    -->
  <!--
     <indexReaderFactory name="IndexReaderFactory" 
                         class="solr.StandardIndexReaderFactory">
       <int name="setTermIndexDivisor">12</int>
     </indexReaderFactory >
    -->

  <!-- ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
       查询部分 - 这里的配置控制着查询期间的事情，比如：缓存。
       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ -->
  <query>
    <!-- 最大布尔型子句


         每条布尔型查询子句的最大长度，如果超出会抛出异常。

         ** 警告 **

         这个选项实际修改了一个能影响Solr全局的Lucene属性。如果多个solrconfig.xml在这个
         属性上不一致，则最终生效的是最后一个值。
         
      -->
    <maxBooleanClauses>1024</maxBooleanClauses>

    <!-- Solr内部查询缓存

         Solr内部有两种缓存实现：
         LRUCache,基于同步的LinkedHashMap。
         FastLRUCache,基于ConcurrentHashMap。

         FastLRUCache可以更快的读和更慢的写，因为是通过单线程操作。这样的话一般来说当缓存命中
         率较高的时候(> 75%)是比LRUCache要快的，而且在多核系统的情况下也要更快。
    -->

    <!-- 过滤器缓存
         
        SolrIndexSearcher过滤器（DocSets）使用的缓存，匹配一个查询的 *all* 文档无序序列。
        当打开一个新的搜索器时，会构建一个缓存或者使用一个旧的搜索器的缓存来"autowarmed"。
        autowarmCount是构建术语的数量。对于LRUCache来说，autowarmed的属于是最近访问的术语。

        参数：
            class - SolrCache的实现，LRUCache或者FastLRUCache。
            size - 缓存最大数量。
            initialSize - 缓存的初始化容量（参考 java.util.HashMap）
            autowarmCount - 要构建的输入数量和旧缓存。
      -->
    <filterCache class="solr.FastLRUCache"
                 size="512"
                 initialSize="512"
                 autowarmCount="0"/>

    <!-- 查询结果缓存
         
         缓存搜索的结果 - 一个有序列表，基于一个查询、一种排序的请求的来的文档。
      -->
    <queryResultCache class="solr.LRUCache"
                     size="512"
                     initialSize="512"
                     autowarmCount="0"/>
   
    <!-- 文档缓存

         缓存Lucene文档对象(每个文档保存的字段)。因为Lucene内部文档比较短，这个缓存将不会自动开启。
      -->
    <documentCache class="solr.LRUCache"
                   size="512"
                   initialSize="512"
                   autowarmCount="0"/>

    <!-- 字段值缓存
        
         动过文档ID来缓存快速房屋的字段。fieldValueCache是默认有效的。
      -->
    <!--
       <fieldValueCache class="solr.FastLRUCache"
                        size="512"
                        autowarmCount="128"
                        showItems="32" />
      -->

    <!-- 自定义缓存
         
         普通缓存的例子。这些缓存可以通过以下方式访问：SolrIndexSearcher.getCache(),
         cacheLookup(),cacheInsert().目的是使用户/应用层的数据可以简单的进行缓存。
         如果要自动生成的话必须为solr.CacheRegenerator指明生成缓存的参数。
      -->
    <!--
       <cache name="myUserCache"
              class="solr.LRUCache"
              size="4096"
              initialSize="1024"
              autowarmCount="1024"
              regenerator="com.mycompany.MyRegenerator"
              />
      -->

    <!-- 字段载入延迟
         
         如果设置为"true",没被请求的字段就会被延迟载入。这对速度优化有这着重要意义，
         因为通常一次查询不需要全部字段，特别是被忽略的字段是个压缩了的大文本字段。
      -->
    <enableLazyFieldLoading>true</enableLazyFieldLoading>

   <!-- 在排序查询中使用过滤器
        
        一个可选的优化方式是通过过滤器来满足搜索条件。如果请求的排序不包括分数，那么
        当过滤器满足一个查询的时候会检查过滤器缓存。如果命中缓存，则过滤器的文档列表
        会作为数据，然后对其进行排序。

        大多数情况下，这都没啥用。除非你频繁重复同一个查询却使用不同的排序方式，而且
        这些货都没用到分数。
     -->
   <!--
      <useFilterForSortedQuery>true</useFilterForSortedQuery>
     -->

   <!-- 结果窗口尺寸

        一种用查询结果缓存来进行的优化方式。当一个搜索请求发出，会获得一个符合条件的
        结果集序列。例如，一个查询语句亲求符合条件的结果的第10至19条，而queryWindowSize设置
        为50，那么结果集的0-49条文档会被收集到缓存中。未来其他在此区间的请求都可以用这个缓存
        来搞定。
     -->
   <queryResultWindowSize>20</queryResultWindowSize>

   <!-- 查询结果缓存为每个输入可以进行缓存的文档数量。-->
   <queryResultMaxDocsCached>200</queryResultMaxDocsCached>

   <!-- 事件触发查询

        各种关联事件的IndexSearcher会在触发监听器时开始运行。

        newSearcher - 当一个新的搜索准备开始而当前有其他搜索请求在进行中的时候触发。它可以用来
        命中最接近缓存来避免一次请求时间过长。

        firstSearcher - 当一个搜索准备开始而当前没有其他搜索请求在处理或获得数据的时候触发。
     -->

    <!-- QuerySenderListener 生成一个数组来保存NamedList和要在本地为对于NamedList执行的查询请求队列。
    
      -->
    <listener event="newSearcher" class="solr.QuerySenderListener">
      <arr name="queries">
        <!--
           <lst><str name="q">solr</str><str name="sort">price asc</str></lst>
           <lst><str name="q">rocks</str><str name="sort">weight asc</str></lst>
          -->
      </arr>
    </listener>
    <listener event="firstSearcher" class="solr.QuerySenderListener">
      <arr name="queries">
        <lst>
          <str name="q">static firstSearcher warming in solrconfig.xml</str>
        </lst>
      </arr>
    </listener>

    <!-- 使用冷搜索器

         如果一个搜索请求过来的时候当前没有注册其他搜索器，那么注册器会马上为它准备并开始使用它。
         如果设置成"false"，所有请求会阻塞到第一个搜索器准备(warming)完成。
      -->
    <useColdSearcher>false</useColdSearcher>

    <!-- 准备(warming)搜索器的数量上限
         
         一次性warming搜索器的最大数量。如果超过这个值会返回一个错误。

         建议只读的slaves设置为1-2，master可以更高。
      -->
    <maxWarmingSearchers>2</maxWarmingSearchers>

  </query>


  <!-- 请求调度器

       这部分包含了当为SolrCore处理请求时SolrDispatchFilter进行的操作指令。

       handleSelect通过这样的方式来影响请求行为：/select?qt=xxx

       handleSelect="true"会导致SolrDispatchFilter去处理请求并根据参数"qt"的值来处理查询

       handleSelect="false"会导致SolrDispatchFilter忽略"/select"请求，如果请求里有"/select"会404。
    -->
  <requestDispatcher handleSelect="true" >
    <!-- 请求解析

         这些设置显示Solr如何解析请求，以及请求内容有什么限制。

         enableRemoteStreaming - 允许使用stream.file和stream.url参数来指定远程数据流。

         multipartUploadLimitInKB - 指明Solr允许的多块文件上传的最大容量。

         *** 警告 ***
         以下设置运行Solr获得远程文件，你在enableRemoteStreaming="true"之前要确保系统提供了相应的用户权限。
      --> 
    <requestParsers enableRemoteStreaming="true" 
                    multipartUploadLimitInKB="2048000" />

    <!-- HTTP缓存

         设置参数关联的HTTP缓存（针对代理和客户端）。

         以下选项指示Solr不要输出HTTP缓存相关的头信息。
      -->
    <httpCaching never304="true" />
    <!-- 如果你包含了<cacheControl>目录，就会用来生成一个Cache-Control头（如果头信息
         包含了"max-age="，页会田间Expires标签。）

         默认情况下，是没有Cache-Control头信息的。

         即使你设置了never304="true"，你仍然可以用<cacheControl>选项。
      -->
    <!--
       <httpCaching never304="true" >
         <cacheControl>max-age=30, public</cacheControl> 
       </httpCaching>
      -->
    <!-- 为了使Solr能够响应带自动生成缓存头信息的请求，并能够准确响应到缓存验证器，应该设置
         never304="false"
         
         这会使Solr生成Last-Modified和Etag头信息到索引里面的属性。

         下面的选项也可以写到头信息里：

         lastModFrom - 默认值是"openTime"，意思是Last-Modified的值（及对应If-Modified-Since的
         请求验证）将全部在搜索请求打开时生效。如果你想要物理索引上次变化的准确值，你可以把它
         改成lastModFrom="dirLastMod"。

         etagSeed="..."，这个选项可以在索引没变的时候强制修改ETag。

         (如果你设置了never304="true"，lastModifiedFrom和etagSeed都会被忽略掉。)
      -->
    <!--
       <httpCaching lastModifiedFrom="openTime"
                    etagSeed="Solr">
         <cacheControl>max-age=30, public</cacheControl> 
       </httpCaching>
      -->
  </requestDispatcher>

  <!-- 请求处理器

       http://wiki.apache.org/solr/SolrRequestHandler

       输入的请求会被调度到path活qt参数指定的处理器来处理。

       "/"开始的访问匹配"/"后面的名字对应的注册器名字。不以"/"开头的请求可以用这样的方式
       访问：http://host/app/[core/]select?qt=name

       如果一个"/select"请求没有声明qt参数，则设置了default="true"的requestHandler会生效。
       
       如果一个请求处理器声明了startup="lazy"，那么在有请求使用它之前是不会初始化的。
    -->
  <!-- SearchHandler

       http://wiki.apache.org/solr/SearchHandler

       为了处理搜索查询，Solr提供的优先的请求处理器是"SearchHandler"。它代表SearchComponents
       结果并支持通过跨多碎片的方式实现分布式查询。
    -->
  <requestHandler name="search" class="solr.SearchHandler" default="true">
    <!-- default values for query parameters can be specified, these
         will be overridden by parameters in the request
      -->
    <!-- 这里可以设置各参数的默认值，这些默认值会被请求的参数覆盖掉。-->
     <lst name="defaults">
       <str name="echoParams">explicit</str>
       <int name="rows">10</int>
     </lst>

    <!-- 除默认值外，还可以用"appends"参数指明附加到查询参数列表的参数值（或者已存在的默认值）-->

    <!-- 在这个例子中，参数"fq=instock:true"会加到每一次用户查询请求中，用来声明一个索引分区机制，
         不受用户声明的过滤查询的影响（可能是faced搜索的一个结果）。

         注意：用户端完全无法操作"appends"参数，所以用这东西之前你要确定你确实要用它。
      -->
    <!--
       <lst name="appends">
         <str name="fq">inStock:true</str>
       </lst>
      -->
    <!-- "invariants"可以使Solr维护者锁定Solr用户端可以使用的选项。这里声明的参数对用户端来说无论是
         设置默认值还是设置"appends"都无法生效。

         在这个例子中，facet.field和facet.query都被锁定了，用户端将无法修改他们。Faceting并不是默认开启
         的 - 但是只要用户端在请求中设置了facet=true，用户端就只能用这里声明的这些facets。用户端声明的
         其他facet.field和facet.query都是无法生效的。

         注意：用户端完全无法操作"invariants"参数，所以用这东西之前你要确定你确实要用它。
      -->
    <!--
       <lst name="invariants">
         <str name="facet.field">cat</str>
         <str name="facet.field">manu_exact</str>
         <str name="facet.query">price:[* TO 500]</str>
         <str name="facet.query">price:[500 TO *]</str>
       </lst>
      -->
    <!-- 如果没有设置SearchComponents的默认值列表，那么这个列表完全可以被覆盖掉，或者可以在默认列表之前/之后
         添加组件（看下面）
      -->
    <!--
       <arr name="components">
         <str>nameOfCustomComponent1</str>
         <str>nameOfCustomComponent2</str>
       </arr>
      -->
    </requestHandler>

  <!-- 默认返回自动缩进JSON格式的请求处理器 -->
  <requestHandler name="/query" class="solr.SearchHandler">
     <lst name="defaults">
       <str name="echoParams">explicit</str>
       <str name="wt">json</str>
       <str name="indent">true</str>
     </lst>
  </requestHandler>


  <!-- 实时查询处理器，不用开新的搜索器活提交就可以获得文档里最新的字段值。当前的实现方式是依赖
       于更新日志特性，所以更新日志功能得开启。
     -->
  <requestHandler name="/get" class="solr.RealTimeGetHandler">
     <lst name="defaults">
       <str name="omitHeader">true</str>
     </lst>
  </requestHandler>

 
  <!-- 一个健壮的例子

       这个示例SearchHandler声明秀一下关闭很多默认值的用处。

       注意一个请求处理器（SearchHandler）的多个实例可以被用不同名字注册多次（而且有不同的初始化参数）。
    -->
  <requestHandler name="/browse" class="solr.SearchHandler">
     <lst name="defaults">
       <str name="echoParams">explicit</str>

       <!-- VelocityResponseWriter设置 -->
       <str name="wt">velocity</str>
       <str name="v.template">browse</str>
       <str name="v.layout">layout</str>
       <str name="title">Solritas</str>

       <!-- 查询设置 -->
       <str name="defType">edismax</str>
       <str name="qf">
          text^0.5 features^1.0 name^1.2 sku^1.5 id^10.0 manu^1.1 cat^1.4
       </str>
       <str name="mm">100%</str>
       <str name="q.alt">*:*</str>
       <str name="rows">10</str>
       <str name="fl">*,score</str>

       <str name="mlt.qf">
         text^0.5 features^1.0 name^1.2 sku^1.5 id^10.0 manu^1.1 cat^1.4
       </str>
       <str name="mlt.fl">text,features,name,sku,id,manu,cat</str>
       <int name="mlt.count">3</int>

       <!-- Facet默认值 -->
       <str name="facet">on</str>
       <str name="facet.field">cat</str>
       <str name="facet.field">manu_exact</str>
       <str name="facet.query">ipod</str>
       <str name="facet.query">GB</str>
       <str name="facet.mincount">1</str>
       <str name="facet.pivot">cat,inStock</str>
       <str name="facet.range.other">after</str>
       <str name="facet.range">price</str>
       <int name="f.price.facet.range.start">0</int>
       <int name="f.price.facet.range.end">600</int>
       <int name="f.price.facet.range.gap">50</int>
       <str name="facet.range">popularity</str>
       <int name="f.popularity.facet.range.start">0</int>
       <int name="f.popularity.facet.range.end">10</int>
       <int name="f.popularity.facet.range.gap">3</int>
       <str name="facet.range">manufacturedate_dt</str>
       <str name="f.manufacturedate_dt.facet.range.start">NOW/YEAR-10YEARS</str>
       <str name="f.manufacturedate_dt.facet.range.end">NOW</str>
       <str name="f.manufacturedate_dt.facet.range.gap">+1YEAR</str>
       <str name="f.manufacturedate_dt.facet.range.other">before</str>
       <str name="f.manufacturedate_dt.facet.range.other">after</str>

       <!-- 高亮设置默认值 -->
       <str name="hl">on</str>
       <str name="hl.fl">text features name</str>
       <str name="f.name.hl.fragsize">0</str>
       <str name="f.name.hl.alternateField">name</str>

       <!-- 拼写检查默认值 -->
       <str name="spellcheck">on</str>
       <str name="spellcheck.collate">true</str>
       <str name="spellcheck.onlyMorePopular">false</str>
       <str name="spellcheck.extendedResults">false</str>
       <str name="spellcheck.count">3</str>
     </lst>

     <!-- 添加拼写检查到我们的组件列表中 -->
     <arr name="last-components">
       <str>spellcheck</str>
     </arr>
  </requestHandler>


  <!-- 更新请求处理器
       
       http://wiki.apache.org/solr/UpdateXmlMessages

       通过XML,JSON,CSV,JAVABIN声明的命理来修改索引的权威的请求处理器。

       注意：从来solr 1.1开始，请求处理器如果内容通过body来post，就需要一个特定的头信息。
       例如：curl现在要请求：-H 'Content-type:text/xml; charset=utf-8'
       
       为了重载请求内容类型并强制设置一个Content-type,请求参数如：
       ?update.contentType=text/csv

       这个处理器会根据'wt'参数的设定格式来获取响应数据。
    -->
  <requestHandler name="/update" class="solr.UpdateRequestHandler">
    <!-- 下面的信息定义了updateRequestProcessorChains,它将确定可以在更新请求中使用的名字。
      -->
    <!--
       <lst name="defaults">
         <str name="update.chain">dedupe</str>
       </lst>
       -->
  </requestHandler>
  

  <!-- Solr细胞更细处理器

       http://wiki.apache.org/solr/ExtractingRequestHandler 

    -->
  <requestHandler name="/update/extract" 
                  startup="lazy"
                  class="solr.extraction.ExtractingRequestHandler" >
    <lst name="defaults">
      <!-- 所有主要内容都放到"text"...如果你需要返回萃取过的文本内容或做高亮处理，
           使用字段。-->
      <str name="fmap.content">text</str>
      <str name="lowernames">true</str>
      <str name="uprefix">ignored_</str>

      <!-- 捕获链接的href属性，但是忽略div属性。 -->
      <str name="captureAttr">true</str>
      <str name="fmap.a">links</str>
      <str name="fmap.div">ignored_</str>
    </lst>
  </requestHandler>


  <!-- 字段分析请求处理器

       请求处理器提供了很多和analysis.jsp相同的功能。提供了在索引时和查询时对同一请求的
       多个字段类型和字段名字进行分析的能力。

       请求参数是：
       analysis.fieldname - 分析器要用的字段名。

       analysis.fieldtype - 分析器要处理的字段类型。

       analysis.fieldvalue - 索引时要分析的文本。

       q (or analysis.q) - 查询时要分析的文本。

       analysis.showmatch (true|false) - 当设置为true并且查询分析器启动了，查询分析生成的这些
                                         字段值分析token会被标记为"matched"。
   -->
  <requestHandler name="/analysis/field" 
                  startup="lazy"
                  class="solr.FieldAnalysisRequestHandler" />


  <!-- 文档分析器

       http://wiki.apache.org/solr/AnalysisRequestHandler

       可以对给定文档进行分析处理的分析器。数据格式如下：

       <docs>
         <doc>
           <field name="id">1</field>
           <field name="name">The Name</field>
           <field name="text">The Text Value</field>
         </doc>
         <doc>...</doc>
         <doc>...</doc>
         ...
       </docs>

    注意：每个文档必须包含一个unique字段。这个字段用来将返回的响应文档和文档分析器关联起来。

    与字段分析器类似，这个处理器也需要在查询请求中通过"analysis.query"或"q"来传递要分析的文本内容。
    也支持"analysis.showmatch"参数（需要设置为true），所有符合匹配查询token的字段token都会标记为"match"。
  -->
  <requestHandler name="/analysis/document" 
                  class="solr.DocumentAnalysisRequestHandler" 
                  startup="lazy" />

  <!-- 管理器

       管理器 - 注册所有的标准的用于管理的处理器。
    -->
  <requestHandler name="/admin/" 
                  class="solr.admin.AdminHandlers" />
  <!-- 这个单个处理器等价于下面那一堆... -->
  <!--
     <requestHandler name="/admin/luke"       class="solr.admin.LukeRequestHandler" />
     <requestHandler name="/admin/system"     class="solr.admin.SystemInfoHandler" />
     <requestHandler name="/admin/plugins"    class="solr.admin.PluginInfoHandler" />
     <requestHandler name="/admin/threads"    class="solr.admin.ThreadDumpHandler" />
     <requestHandler name="/admin/properties" class="solr.admin.PropertiesRequestHandler" />
     <requestHandler name="/admin/file"       class="solr.admin.ShowFileRequestHandler" >
    -->

  <!-- 如果你希望隐藏${solr.home}/conf下面的文件，显示注册ShowFileRequestHandler: -->
  <!--
     <requestHandler name="/admin/file" 
                     class="solr.admin.ShowFileRequestHandler" >
       <lst name="invariants">
         <str name="hidden">synonyms.txt</str> 
         <str name="hidden">anotherfile.txt</str> 
       </lst>
     </requestHandler>
    -->

  <!-- ping/healthcheck -->
  <requestHandler name="/admin/ping" class="solr.PingRequestHandler">
    <lst name="invariants">
      <str name="q">solrpingquery</str>
    </lst>
    <lst name="defaults">
      <str name="echoParams">all</str>
    </lst>

    <!-- PingRequestHandler的一个可选特性是通过给处理器配置"healthcheckFile"来启用/禁用PingRequestHandler。
         相关路径在data目录下。 -->
    <!-- <str name="healthcheckFile">server-enabled.txt</str> -->
  </requestHandler>

  <!-- 回显请求内容给客户端 -->
  <requestHandler name="/debug/dump" class="solr.DumpRequestHandler" >
    <lst name="defaults">
     <str name="echoParams">explicit</str> 
     <str name="echoHandler">true</str>
    </lst>
  </requestHandler>
  
  <!-- Solr Replication

       SolrReplicationHandler支持通过查询来对索引进行主从同步。

       http://wiki.apache.org/solr/SolrReplication 

       下面的例子中，如果是在slave就移除<lst name="master">,如果是slave就移除<lst name="slave">。
    -->
  <!--
     <requestHandler name="/replication" class="solr.ReplicationHandler" >
       <lst name="master">
         <str name="replicateAfter">commit</str>
         <str name="replicateAfter">startup</str>
         <str name="confFiles">schema.xml,stopwords.txt</str>
       </lst>
       <lst name="slave">
         <str name="masterUrl">http://localhost:8983/solr/replication</str>
         <str name="pollInterval">00:00:60</str>
       </lst>
     </requestHandler>
    -->
    
    <!-- Solr Replication用于SolrCloud的恢复
    
         这是SolrCloud的恢复需要的配置。
    -->
	<requestHandler name="/replication" class="solr.ReplicationHandler" startup="lazy" /> 


  <!-- 搜索组件

       注册了的搜索组件会被搜索处理器实例调用（可以通过名字来访问）
       
       默认情况下，下面组件是有效的：
       
       <searchComponent name="query"     class="solr.QueryComponent" />
       <searchComponent name="facet"     class="solr.FacetComponent" />
       <searchComponent name="mlt"       class="solr.MoreLikeThisComponent" />
       <searchComponent name="highlight" class="solr.HighlightComponent" />
       <searchComponent name="stats"     class="solr.StatsComponent" />
       <searchComponent name="debug"     class="solr.DebugComponent" />
   
       一个处理器的默认配置是像下面这样的：

       <arr name="components">
         <str>query</str>
         <str>facet</str>
         <str>mlt</str>
         <str>highlight</str>
         <str>stats</str>
         <str>debug</str>
       </arr>

       如果你使用标准名字注册一个搜索组件，默认的将被覆盖掉。

       要在标准组件之前或之后加入组件，要这么搞：
    
       <arr name="first-components">
         <str>myFirstComponentName</str>
       </arr>
    
       <arr name="last-components">
         <str>myLastComponentName</str>
       </arr>

       注意："debug"组件总是在最后。
     -->
  
   <!-- 拼写检查

        拼写检查组件会返回一些可选的拼写建议。

        http://wiki.apache.org/solr/SpellCheckComponent
     -->
  <searchComponent name="spellcheck" class="solr.SpellCheckComponent">

    <str name="queryAnalyzerFieldType">textSpell</str>

    <!-- 这个组件会用到很多拼写检查器。 -->

    <!-- 一个为主索引的某字段建立的拼写检查器 -->
    <lst name="spellchecker">
      <str name="name">default</str>
      <str name="field">name</str>
      <str name="classname">solr.DirectSolrSpellChecker</str>
      <!-- 拼写检查测量距离可用，默认是内部的莱文斯坦实现。 -->
      <str name="distanceMeasure">internal</str>
      <!-- 最小准确率需要和正确拼写建议有关 -->
      <float name="accuracy">0.5</float>
      <!-- 最大编辑值的可能值是枚举型的：1,2 -->
      <int name="maxEdits">2</int>
      <!-- 枚举属于时最小共享前缀 -->
      <int name="minPrefix">1</int>
      <!-- 每次结果检查的最大次数 -->
      <int name="maxInspections">5</int>
      <!-- 一个查询中准确部分的最小长度 -->
      <int name="minQueryLength">4</int>
      <!-- 一个获得准确查询的最大入口数 -->
      <float name="maxQueryFrequency">0.01</float>
      <!-- 去掉这个注视可以在0.1%的文档中提供拼写建议
      	<float name="thresholdTokenFrequency">.01</float>
      -->
    </lst>

    <!-- 拼写检查器用在不同的相似度衡量的情况下 -->
    <!--
       <lst name="spellchecker">
         <str name="name">jarowinkler</str>
         <str name="field">spell</str>
         <str name="classname">solr.DirectSolrSpellChecker</str>
         <str name="distanceMeasure">
           org.apache.lucene.search.spell.JaroWinklerDistance
         </str>
       </lst>
     -->

    <!-- 使用不同比较器的拼写检查器

         比较器类可选值：
          1. score (默认)
          2. freq (频率优先，分数其次)
          3. 一个完整的类名
      -->
    <!--
       <lst name="spellchecker">
         <str name="name">freq</str>
         <str name="field">lowerfilt</str>
         <str name="classname">solr.DirectSolrSpellChecker</str>
         <str name="comparatorClass">freq</str>
      -->

    <!-- 从文件中读取单词列表的拼写检查器 -->
    <!--
       <lst name="spellchecker">
         <str name="classname">solr.FileBasedSpellChecker</str>
         <str name="name">file</str>
         <str name="sourceLocation">spellings.txt</str>
         <str name="characterEncoding">UTF-8</str>
         <str name="spellcheckIndexDir">spellcheckerFile</str>
       </lst>
      -->
  </searchComponent>

  <!-- 一个包含拼写检查组件的请求处理器

       注意：这个是简单的例子。SpellCheckComponent组件的目的是作为够子挂到请求处理器当中去，确保
       用户的查询请求不用一个一个的获得拼写建议。

       换句话说，下面这个配置不适合放到生产环境中去！！！
       
       详见：http://wiki.apache.org/solr/SpellCheckComponent
       -->
  <requestHandler name="/spell" class="solr.SearchHandler" startup="lazy">
    <lst name="defaults">
      <str name="spellcheck.onlyMorePopular">false</str>
      <str name="spellcheck.extendedResults">false</str>
      <str name="spellcheck.count">1</str>
    </lst>
    <arr name="last-components">
      <str>spellcheck</str>
    </arr>
  </requestHandler>

  <!-- 术语向量组件

       http://wiki.apache.org/solr/TermVectorComponent
    -->
  <searchComponent name="tvComponent" class="solr.TermVectorComponent"/>

  <!-- 使用属于向量组件的处理器。

       这是个简单的例子。

       实际情况中，你可能会把这组件加到你已有的请求处理器中。
    -->
  <requestHandler name="tvrh" class="solr.SearchHandler" startup="lazy">
    <lst name="defaults">
      <bool name="tv">true</bool>
    </lst>
    <arr name="last-components">
      <str>tvComponent</str>
    </arr>
  </requestHandler>

  <!-- 集群组件

       http://wiki.apache.org/solr/ClusteringComponent

       当你想要在solr上使用集群的话，你需要设置solr.cluster.enabled的系统属性

            java -Dsolr.clustering.enabled=true -jar start.jar

    -->
  <searchComponent name="clustering"
                   enable="${solr.clustering.enabled:false}"
                   class="solr.clustering.ClusteringComponent" >
    <!-- 声明一个引擎 -->
    <lst name="engine">
      <!-- 名字，只能有一个叫"default" -->
      <str name="name">default</str>

      <!-- Carrot2集群算法的类名。

           当前可用算法如下：
           
           * org.carrot2.clustering.lingo.LingoClusteringAlgorithm
           * org.carrot2.clustering.stc.STCClusteringAlgorithm
           * org.carrot2.clustering.kmeans.BisectingKMeansClusteringAlgorithm
           
           详见 http://project.carrot2.org/algorithms.html 的算法部分
        -->
      <str name="carrot.algorithm">org.carrot2.clustering.lingo.LingoClusteringAlgorithm</str>

      <!-- 重载Carrot2默认算法的属性值。

           关于所有可用属性的描述，参见：
           http://download.carrot2.org/stable/manual/#chapter.components.
           使用属性键作为下面字符串元素的属性名。这些可以通过请求参数来重载。
        -->
      <str name="LingoClusteringAlgorithm.desiredClusterCountBase">20</str>

      <!-- Carrot2字典资源的位置

           Carrot2算法载入字典和标签的目录。Solr配置中的绝对或相对路径。如果声明了一个专门的资源（比如：stopwords.en）
           则会完全覆盖掉默认的对应值。

           要了解Carrot2字典资源，参见：
           http://download.carrot2.org/head/manual/#chapter.lexical-resources
        -->
      <str name="carrot.lexicalResourcesDir">clustering/carrot2</str>

      <!-- 文档数据使用的语言

           下面是运行使用的语言的可能值列表：
           http://download.carrot2.org/stable/manual/#section.attribute.lingo.MultilingualClustering.defaultLanguage
       -->
      <str name="MultilingualClustering.defaultLanguage">ENGLISH</str>
    </lst>
    <lst name="engine">
      <str name="name">stc</str>
      <str name="carrot.algorithm">org.carrot2.clustering.stc.STCClusteringAlgorithm</str>
    </lst>
  </searchComponent>

  <!-- 使用集群组件的请求处理器

       这只是个简单的例子。

       实际应用中你可能会把组件加到你已经在用的请求处理器。
    -->
  <requestHandler name="/clustering"
                  startup="lazy"
                  enable="${solr.clustering.enabled:false}"
                  class="solr.SearchHandler">
    <lst name="defaults">
      <bool name="clustering">true</bool>
      <str name="clustering.engine">default</str>
      <bool name="clustering.results">true</bool>
      <!-- 字段名 -->
      <str name="carrot.title">name</str>
      <str name="carrot.url">id</str>
      <!-- 使用集群的字段 -->
       <str name="carrot.snippet">features</str>
       <!-- 生成摘要 -->
       <bool name="carrot.produceSummary">true</bool>
       <!-- 每个集群的标签上限 -->
       <!--<int name="carrot.numDescriptions">5</int>-->

       <!-- 生成子集群 -->
       <bool name="carrot.outputSubClusters">false</bool>
       
       <str name="defType">edismax</str>
       <str name="qf">
         text^0.5 features^1.0 name^1.2 sku^1.5 id^10.0 manu^1.1 cat^1.4
       </str>
       <str name="q.alt">*:*</str>
       <str name="rows">10</str>
       <str name="fl">*,score</str>
    </lst>     
    <arr name="last-components">
      <str>clustering</str>
    </arr>
  </requestHandler>
  
  <!-- 术语组件

       http://wiki.apache.org/solr/TermsComponent

       获得文档使用各术语的频率。
    -->
  <searchComponent name="terms" class="solr.TermsComponent"/>

  <!-- 使用术语组件的请求处理器 -->
  <requestHandler name="/terms" class="solr.SearchHandler" startup="lazy">
     <lst name="defaults">
      <bool name="terms">true</bool>
    </lst>     
    <arr name="components">
      <str>terms</str>
    </arr>
  </requestHandler>


  <!-- 查询前置组件

       http://wiki.apache.org/solr/QueryElevationComponent

       这个组件可以让你通过配置把分数不高的搜速结果放到结果集的前排位置。
    -->
  <searchComponent name="elevator" class="solr.QueryElevationComponent" >
    <!-- 取得用于分析查询的字段类型 -->
    <str name="queryFieldType">string</str>
    <str name="config-file">elevate.xml</str>
  </searchComponent>

  <!-- 使用前置组件的请求处理器 -->
  <requestHandler name="/elevate" class="solr.SearchHandler" startup="lazy">
    <lst name="defaults">
      <str name="echoParams">explicit</str>
    </lst>
    <arr name="last-components">
      <str>elevator</str>
    </arr>
  </requestHandler>

  <!-- 高亮组件

       http://wiki.apache.org/solr/HighlightingParameters
    -->
  <searchComponent class="solr.HighlightComponent" name="highlight">
    <highlighting>
      <!-- 配置标准片段 -->
      <!-- 这部分通常情况下是被注释掉的。 -->
      <fragmenter name="gap" 
                  default="true"
                  class="solr.highlight.GapFragmenter">
        <lst name="defaults">
          <int name="hl.fragsize">100</int>
        </lst>
      </fragmenter>

      <!-- 基于正则的片段匹配（为了提取句子） -->
      <fragmenter name="regex" 
                  class="solr.highlight.RegexFragmenter">
        <lst name="defaults">
          <!-- 稍微小点的片段大小会比较好，因为冗余的考虑。 -->
          <int name="hl.fragsize">70</int>
          <!-- 每个匹配片段允许50%的冗余 -->
          <float name="hl.regex.slop">0.5</float>
          <!-- 一个基本的句子表达式 -->
          <str name="hl.regex.pattern">[-\w ,/\n\&quot;&apos;]{20,200}</str>
        </lst>
      </fragmenter>

      <!-- 配置标准格式器 -->
      <formatter name="html" 
                 default="true"
                 class="solr.highlight.HtmlFormatter">
        <lst name="defaults">
          <str name="hl.simple.pre"><![CDATA[<em>]]></str>
          <str name="hl.simple.post"><![CDATA[</em>]]></str>
        </lst>
      </formatter>

      <!-- 配置标准编码器 -->
      <encoder name="html" 
               class="solr.highlight.HtmlEncoder" />

      <!-- 配置标准fragListBuilder -->
      <fragListBuilder name="simple" 
                       default="true"
                       class="solr.highlight.SimpleFragListBuilder"/>

      <!-- 配置单个fragListBuilder -->
      <fragListBuilder name="single" 
                       class="solr.highlight.SingleFragListBuilder"/>

      <!-- 默认的FragmentsBuilder -->
      <fragmentsBuilder name="default" 
                        default="true"
                        class="solr.highlight.ScoreOrderFragmentsBuilder">
        <!-- 
        <lst name="defaults">
          <str name="hl.multiValuedSeparatorChar">/</str>
        </lst>
        -->
      </fragmentsBuilder>

      <!-- 彩色FragmentsBuilder -->
      <fragmentsBuilder name="colored" 
                        class="solr.highlight.ScoreOrderFragmentsBuilder">
        <lst name="defaults">
          <str name="hl.tag.pre"><![CDATA[
               <b style="background:yellow">,<b style="background:lawgreen">,
               <b style="background:aquamarine">,<b style="background:magenta">,
               <b style="background:palegreen">,<b style="background:coral">,
               <b style="background:wheat">,<b style="background:khaki">,
               <b style="background:lime">,<b style="background:deepskyblue">]]></str>
          <str name="hl.tag.post"><![CDATA[</b>]]></str>
        </lst>
      </fragmentsBuilder>
      
      <boundaryScanner name="default" 
                       default="true"
                       class="solr.highlight.SimpleBoundaryScanner">
        <lst name="defaults">
          <str name="hl.bs.maxScan">10</str>
          <str name="hl.bs.chars">.,!? &#9;&#10;&#13;</str>
        </lst>
      </boundaryScanner>
      
      <boundaryScanner name="breakIterator" 
                       class="solr.highlight.BreakIteratorBoundaryScanner">
        <lst name="defaults">
          <!-- 类型可能值：CHARACTER,WORD(默认),LINE,SENTENCE -->
          <str name="hl.bs.type">WORD</str>
          <!-- 本地化的时候需要配置国家和语言 -->
          <!-- 在获得BreakIterator实例时会进行本地化 -->
          <str name="hl.bs.language">en</str>
          <str name="hl.bs.country">US</str>
        </lst>
      </boundaryScanner>
    </highlighting>
  </searchComponent>

  <!-- 更新处理器

       关于处理更新请求的更新处理器的相关约束参见：

       http://wiki.apache.org/solr/UpdateRequestProcessor

    --> 
  <!-- 拆分

       下面是一个创建了"id"字段的例子，"id"字段由其他字段的哈希码生成。这个例子中，在我们使用了"id"字段
       作为签名字段后进行了二次拆分，solr会维护它的唯一性。
    -->
  <!--
     <updateRequestProcessorChain name="dedupe">
       <processor class="solr.processor.SignatureUpdateProcessorFactory">
         <bool name="enabled">true</bool>
         <str name="signatureField">id</str>
         <bool name="overwriteDupes">false</bool>
         <str name="fields">name,features,cat</str>
         <str name="signatureClass">solr.processor.Lookup3Signature</str>
       </processor>
       <processor class="solr.LogUpdateProcessorFactory" />
       <processor class="solr.RunUpdateProcessorFactory" />
     </updateRequestProcessorChain>
    -->
  
  <!-- 语言定义

       这个例子更新了根据语言ID属性传进来的文档的定义约束。检测到的语言会写道language_s字段。没有建立名字映射。
       语言检测的字段包括：text,title,subject和description。这个例子很好的展示了通过ExtractingRequestHandler
       进行语言检测后构造富文本全文搜索。

       更多语言相关信息参考：http://wiki.apache.org/solr/LanguageDetection
    -->
    <!--
     <updateRequestProcessorChain name="langid">
       <processor class="org.apache.solr.update.processor.TikaLanguageIdentifierUpdateProcessorFactory">
         <str name="langid.fl">text,title,subject,description</str>
         <str name="langid.langField">language_s</str>
         <str name="langid.fallback">en</str>
       </processor>
       <processor class="solr.LogUpdateProcessorFactory" />
       <processor class="solr.RunUpdateProcessorFactory" />
     </updateRequestProcessorChain>
    -->
 
  <!-- 响应写入器

       http://wiki.apache.org/solr/QueryResponseWriter

       请求的响应需要由"wt"参数指定的写入器来进行响应操作。

       如果请求里没声明"wt"参数，则默认写入器是"default"。
    -->

  <!-- 以下响应写入器在被覆盖之前是有效的...  -->

  <!--
     <queryResponseWriter name="xml" 
                          default="true"
                          class="solr.XMLResponseWriter" />
     <queryResponseWriter name="json" class="solr.JSONResponseWriter"/>
     <queryResponseWriter name="python" class="solr.PythonResponseWriter"/>
     <queryResponseWriter name="ruby" class="solr.RubyResponseWriter"/>
     <queryResponseWriter name="php" class="solr.PHPResponseWriter"/>
     <queryResponseWriter name="phps" class="solr.PHPSerializedResponseWriter"/>
     <queryResponseWriter name="csv" class="solr.CSVResponseWriter"/>
    -->

  <queryResponseWriter name="json" class="solr.JSONResponseWriter">
     <!-- 为配合这个教程，JSON响应器以文本方式响应这样就可以跨浏览器了...
          如果你希望使用"application/json"的MIME类型，那把这里的部分删掉就行了。
     -->
    <str name="content-type">text/plain; charset=UTF-8</str>
  </queryResponseWriter>
  
  <!--
     根据需要设置响应写入器
    -->
    <queryResponseWriter name="velocity" class="solr.VelocityResponseWriter" startup="lazy"/>
  

  <!-- XSLT响应器会把XML根据Solr的conf/xslt目录下的xslt进行输出。xslt文件的切换频率要看xsltCacheLifetimeSeconds。
    -->
  <queryResponseWriter name="xslt" class="solr.XSLTResponseWriter">
    <int name="xsltCacheLifetimeSeconds">5</int>
  </queryResponseWriter>

  <!-- 查询解析器

       http://wiki.apache.org/solr/SolrQuerySyntax

       可以通过名字注册多个QParserPlugins，并且可以通过QueryComponent或LocalParams的"defType"参数来调用。
    -->
  <!-- 注册查询解析器的例子 -->
  <!--
     <queryParser name="myparser" class="com.mycompany.MyQParserPlugin"/>
    -->

  <!-- 函数解析器

       http://wiki.apache.org/solr/FunctionQuery

       可以通过名字注册多个ValueSourceParsers,然后通过给"func"赋函数名来使用。
    -->
  <!-- 注册自定义函数解析器的例子 -->
  <!--
     <valueSourceParser name="myfunc" 
                        class="com.mycompany.MyValueSourceParser" />
    -->
    
  
  <!-- 文档转换器
       http://wiki.apache.org/solr/DocTransformers
    -->
  <!--
     类似这个样子:
     <transformer name="db" class="com.mycompany.LoadFromDatabaseTransformer" >
       <int name="connection">jdbc://....</int>
     </transformer>
     
     为所有文档声明一个常量:
     <transformer name="mytrans2" class="org.apache.solr.response.transform.ValueAugmenterFactory" >
       <int name="value">5</int>
     </transformer>
     
     如果希望用可以通过 _value:something_ 的方式修改它的话，你可以这么搞：
     <transformer name="mytrans3" class="org.apache.solr.response.transform.ValueAugmenterFactory" >
       <double name="defaultValue">5</double>
     </transformer>

     如果你使用QueryElevationComponent，你可能希望标记高频率文档。EditorialMarkerFactory可以很好的做到：
     <transformer name="qecBooster" class="org.apache.solr.response.transform.EditorialMarkerFactory" />
    -->
    

  <!-- 最后是管理接口的配置 -->
  <admin>
    <defaultQuery>*:*</defaultQuery>
  </admin>

</config>
